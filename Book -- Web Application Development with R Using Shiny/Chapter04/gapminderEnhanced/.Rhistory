df_title <- data.frame(doc_id = row.names(subsetData),
text = subsetData$Best)
mycorpus = Corpus(DataframeSource(df_title))
crude <- tm_map(mycorpus, removePunctuation)
crude <- tm_map(crude, function(x) removeWords(x, c("Nothing", "they", "dont", stopwords())))
# demoFreq is a data.frame including word and freq in each colum
tdm <- TermDocumentMatrix(crude)
m <- as.matrix(tdm)
v <- sort(rowSums(m), decreasing = TRUE)
demoFreq <- data.frame(word = names(v), freq=v)
wordcloud2(demoFreq[1:400, ], figPath = "~/Nextcloud/Presentations/tidyText/nhs.png", size = 1.5)
getwd()
library(syuzhet)
library(tm)
library(wordcloud)
tweets = get_nrc_sentiment(subsetData$Improve)
library(tidyverse)
library(tidytext)
library(pander)
library(knitr)
library(magrittr)
load("~/shiny.Rdata")
set.seed(2014)
subsetData = trustData %>%
filter(!is.na(Improve), !is.na(Best)) %>%
sample_n(5000)
library(syuzhet)
library(tm)
library(wordcloud)
# get the sentiment scores for the tweets
tweets = get_nrc_sentiment(subsetData$Improve)
tweets$Improve = subsetData$Improve
all = c(
paste(tweets$Improve[tweets$anger > 0], collapse=" "),
paste(tweets$Improve[tweets$anticipation > 0], collapse=" "),
paste(tweets$Improve[tweets$disgust > 0], collapse=" "),
paste(tweets$Improve[tweets$fear > 0], collapse=" "),
paste(tweets$Improve[tweets$joy > 0], collapse=" "),
paste(tweets$Improve[tweets$sadness > 0], collapse=" "),
paste(tweets$Improve[tweets$surprise > 0], collapse=" "),
paste(tweets$Improve[tweets$trust > 0], collapse=" ")
)
# clean the text
clean.text = function(x)
{
# tolower
x = tolower(x)
# remove rt
x = gsub("rt", "", x)
# remove at
x = gsub("@\\w+", "", x)
# remove punctuation
x = gsub("[[:punct:]]", "", x)
# remove numbers
x = gsub("[[:digit:]]", "", x)
# remove links http
x = gsub("http\\w+", "", x)
# remove tabs
x = gsub("[ |\t]{2,}", "", x)
# remove blank spaces at the beginning
x = gsub("^ ", "", x)
# remove blank spaces at the end
x = gsub(" $", "", x)
return(x)
}
all = clean.text(all)
# remove stop-words
# adding extra domain specific stop words
all = removeWords(all, c(stopwords("english"), "rampton"))
# create corpus
corpus = Corpus(VectorSource(all))
# create term-document matrix
tdm = TermDocumentMatrix(corpus)
# convert as matrix
tdm = as.matrix(tdm)
# add column names
colnames(tdm) = c('anger', 'anticipation', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'trust')
# Plot comparison wordcloud
layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, 'Emotion Comparison Word Cloud')
comparison.cloud(tdm, random.order=FALSE,
colors = c("#00B2FF", "red", "#FF0099", "#6600CC", "green", "orange", "blue", "brown"),
title.size=1.5, max.words=250)
# Plot comparison wordcloud
# layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
# par(mar=rep(0, 4))
# plot.new()
# text(x=0.5, y=0.5, 'Emotion Comparison Word Cloud')
comparison.cloud(tdm, random.order=FALSE,
colors = c("#00B2FF", "red", "#FF0099", "#6600CC", "green", "orange", "blue", "brown"),
# title.size=1.5,
max.words=250)
# create corpus
corpus = Corpus(VectorSource(all))
# create term-document matrix
tdm = TermDocumentMatrix(corpus)
# convert as matrix
tdm = as.matrix(tdm)
# add column names
colnames(tdm) = c('anger', 'anticipation', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'trust')
# Plot comparison wordcloud
# layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
# par(mar=rep(0, 4))
# plot.new()
# text(x=0.5, y=0.5, 'Emotion Comparison Word Cloud')
comparison.cloud(tdm, random.order=FALSE,
colors = c("#00B2FF", "red", "#FF0099", "#6600CC", "green", "orange", "blue", "brown"),
# title.size=1.5,
max.words=250)
library(tidyverse)
library(tidytext)
library(pander)
library(knitr)
library(magrittr)
load("~/shiny.Rdata")
set.seed(2014)
subsetData = trustData %>%
filter(!is.na(Improve), !is.na(Best)) %>%
sample_n(5000)
library(syuzhet)
library(tm)
library(wordcloud)
# get the sentiment scores for the tweets
nrcComments = get_nrc_sentiment(subsetData$Improve)
all = c(
paste(nrcComments$Improve[nrcComments$anger > 0], collapse=" "),
paste(nrcComments$Improve[nrcComments$anticipation > 0], collapse=" "),
paste(nrcComments$Improve[nrcComments$disgust > 0], collapse=" "),
paste(nrcComments$Improve[nrcComments$fear > 0], collapse=" "),
paste(nrcComments$Improve[nrcComments$joy > 0], collapse=" "),
paste(nrcComments$Improve[nrcComments$sadness > 0], collapse=" "),
paste(nrcComments$Improve[nrcComments$surprise > 0], collapse=" "),
paste(nrcComments$Improve[nrcComments$trust > 0], collapse=" ")
)
# ... some boring code hidden, I'll distribute the code if anyone wants it
# clean the text
clean.text = function(x)
{
# tolower
x = tolower(x)
# remove rt
x = gsub("rt", "", x)
# remove at
x = gsub("@\\w+", "", x)
# remove punctuation
x = gsub("[[:punct:]]", "", x)
# remove numbers
x = gsub("[[:digit:]]", "", x)
# remove links http
x = gsub("http\\w+", "", x)
# remove tabs
x = gsub("[ |\t]{2,}", "", x)
# remove blank spaces at the beginning
x = gsub("^ ", "", x)
# remove blank spaces at the end
x = gsub(" $", "", x)
return(x)
}
all = clean.text(all)
# remove stop-words
# adding extra domain specific stop words
all = removeWords(all, c(stopwords("english"), "rampton"))
# create corpus
corpus = Corpus(VectorSource(all))
# create term-document matrix
tdm = TermDocumentMatrix(corpus)
# convert as matrix
tdm = as.matrix(tdm)
# add column names
colnames(tdm) = c('anger', 'anticipation', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'trust')
# Plot comparison wordcloud
# layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
# par(mar=rep(0, 4))
# plot.new()
# text(x=0.5, y=0.5, 'Emotion Comparison Word Cloud')
comparison.cloud(tdm, random.order=FALSE,
colors = c("#00B2FF", "red", "#FF0099", "#6600CC", "green", "orange", "blue", "brown"),
# title.size=1.5,
max.words=250)
all
nrcComments = get_nrc_sentiment(subsetData$Improve)
all = c(
paste(nrcComments$Improve[nrcComments$anger > 0], collapse=" "),
paste(nrcComments$Improve[nrcComments$anticipation > 0], collapse=" "),
paste(nrcComments$Improve[nrcComments$disgust > 0], collapse=" "),
paste(nrcComments$Improve[nrcComments$fear > 0], collapse=" "),
paste(nrcComments$Improve[nrcComments$joy > 0], collapse=" "),
paste(nrcComments$Improve[nrcComments$sadness > 0], collapse=" "),
paste(nrcComments$Improve[nrcComments$surprise > 0], collapse=" "),
paste(nrcComments$Improve[nrcComments$trust > 0], collapse=" ")
)
all
nrcComments$Improve
nrcComments$anger
str(nrcComments)
all = c(
paste(nrcComments$anger[nrcComments$anger > 0], collapse=" "),
paste(nrcComments$anticipation[nrcComments$anticipation > 0], collapse=" "),
paste(nrcComments$disgust[nrcComments$disgust > 0], collapse=" "),
paste(nrcComments$fear[nrcComments$fear > 0], collapse=" "),
paste(nrcComments$joy[nrcComments$joy > 0], collapse=" "),
paste(nrcComments$sadness[nrcComments$sadness > 0], collapse=" "),
paste(nrcComments$surprise[nrcComments$surprise > 0], collapse=" "),
paste(nrcComments$trust[nrcComments$trust > 0], collapse=" ")
)
all
clean.text = function(x)
{
# tolower
x = tolower(x)
# remove rt
x = gsub("rt", "", x)
# remove at
x = gsub("@\\w+", "", x)
# remove punctuation
x = gsub("[[:punct:]]", "", x)
# remove numbers
x = gsub("[[:digit:]]", "", x)
# remove links http
x = gsub("http\\w+", "", x)
# remove tabs
x = gsub("[ |\t]{2,}", "", x)
# remove blank spaces at the beginning
x = gsub("^ ", "", x)
# remove blank spaces at the end
x = gsub(" $", "", x)
return(x)
}
all = clean.text(all)
# remove stop-words
# adding extra domain specific stop words
all = removeWords(all, c(stopwords("english"), "rampton"))
# create corpus
corpus = Corpus(VectorSource(all))
# create term-document matrix
tdm = TermDocumentMatrix(corpus)
# convert as matrix
tdm = as.matrix(tdm)
# add column names
colnames(tdm) = c('anger', 'anticipation', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'trust')
# Plot comparison wordcloud
layout(matrix(c(1, 2), nrow=2), heights=c(1, 4))
par(mar=rep(0, 4))
plot.new()
text(x=0.5, y=0.5, 'Emotion Comparison Word Cloud')
comparison.cloud(tdm, random.order = FALSE,
colors = c("#00B2FF", "red", "#FF0099", "#6600CC", "green", "orange", "blue", "brown"),
title.size=1.5, max.words = 250)
all
all = c(
paste(nrcComments$anger[nrcComments$anger > 0], collapse=" "),
paste(nrcComments$anticipation[nrcComments$anticipation > 0], collapse=" "),
paste(nrcComments$disgust[nrcComments$disgust > 0], collapse=" "),
paste(nrcComments$fear[nrcComments$fear > 0], collapse=" "),
paste(nrcComments$joy[nrcComments$joy > 0], collapse=" "),
paste(nrcComments$sadness[nrcComments$sadness > 0], collapse=" "),
paste(nrcComments$surprise[nrcComments$surprise > 0], collapse=" "),
paste(nrcComments$trust[nrcComments$trust > 0], collapse=" ")
)
all
# library(devtools)
# devtools::install_github("lchiffon/wordcloud2")
library(tm)
library(wordcloud2)
library(webshot)
library("htmlwidgets")
df_title <- data.frame(doc_id = row.names(subsetData),
text = subsetData$Best)
mycorpus = Corpus(DataframeSource(df_title))
corpusmap <- tm_map(mycorpus, removePunctuation)
corpusmap <- tm_map(corpusmap, function(x) removeWords(x, c("Nothing", "they", "dont", stopwords())))
# demoFreq is a data.frame including word and freq in each colum
tdm <- TermDocumentMatrix(corpusmap)
m <- as.matrix(tdm)
v <- sort(rowSums(m), decreasing = TRUE)
demoFreq <- data.frame(word = names(v), freq = v)
wordcloud2(demoFreq[1:400, ], figPath = "~/Nextcloud/Presentations/tidyText/nhs.png", size = 1.5)
library(tm)
library(wordcloud2)
# create corpus
corpus = Corpus(VectorSource(all))
# create term-document matrix
tdm = TermDocumentMatrix(corpus)
# convert as matrix
tdm = as.matrix(tdm)
# add column names
colnames(tdm) = c('anger', 'anticipation', 'disgust', 'fear',
'joy', 'sadness', 'surprise', 'trust')
# Plot comparison wordcloud
layout(matrix(c(1, 2), nrow = 2), heights = c(1, 4))
par(mar = rep(0, 4))
plot.new()
text(x = 0.5, y=0.5, 'Emotion Comparison Word Cloud')
comparison.cloud(tdm, random.order=FALSE,
colors = c("#00B2FF", "red", "#FF0099", "#6600CC",
"green", "orange", "blue", "brown"),
title.size = 1.5, max.words = 250)
# clean the text
clean.text = function(x)
{
# tolower
x = tolower(x)
# remove rt
x = gsub("rt", "", x)
# remove at
x = gsub("@\\w+", "", x)
# remove punctuation
x = gsub("[[:punct:]]", "", x)
# remove numbers
x = gsub("[[:digit:]]", "", x)
# remove links http
x = gsub("http\\w+", "", x)
# remove tabs
x = gsub("[ |\t]{2,}", "", x)
# remove blank spaces at the beginning
x = gsub("^ ", "", x)
# remove blank spaces at the end
x = gsub(" $", "", x)
return(x)
}
all = clean.text(all)
# remove stop-words
# adding extra domain specific stop words
all = removeWords(all, c(stopwords("english"), "rampton"))
library(syuzhet)
library(tm)
library(wordcloud)
# get the sentiment scores for the tweets
nrcComments = get_nrc_sentiment(subsetData$Improve)
# put the text in
nrcComments$Text = subsetData$Improve
all = c(
paste(nrcComments$Text[nrcComments$anger > 0], collapse=" "),
paste(nrcComments$Text[nrcComments$anticipation > 0], collapse=" "),
paste(nrcComments$Text[nrcComments$disgust > 0], collapse=" "),
paste(nrcComments$Text[nrcComments$fear > 0], collapse=" "),
paste(nrcComments$Text[nrcComments$joy > 0], collapse=" "),
paste(nrcComments$Text[nrcComments$sadness > 0], collapse=" "),
paste(nrcComments$Text[nrcComments$surprise > 0], collapse=" "),
paste(nrcComments$Text[nrcComments$trust > 0], collapse=" ")
)
# ... some boring code hidden, I'll distribute the code if anyone wants it
nrcComments = get_nrc_sentiment(subsetData$Improve)
library(tidyverse)
library(tidytext)
library(pander)
library(knitr)
library(magrittr)
library(tm)
library(wordcloud2)
load("~/shiny.Rdata")
set.seed(2014)
subsetData = trustData %>%
filter(!is.na(Improve), !is.na(Best)) %>%
sample_n(5000)
library(syuzhet)
library(tm)
library(wordcloud)
# get the sentiment scores for the tweets
nrcComments = get_nrc_sentiment(subsetData$Improve)
# put the text in
nrcComments$Text = subsetData$Improve
all = c(
paste(nrcComments$Text[nrcComments$anger > 0], collapse=" "),
paste(nrcComments$Text[nrcComments$anticipation > 0], collapse=" "),
paste(nrcComments$Text[nrcComments$disgust > 0], collapse=" "),
paste(nrcComments$Text[nrcComments$fear > 0], collapse=" "),
paste(nrcComments$Text[nrcComments$joy > 0], collapse=" "),
paste(nrcComments$Text[nrcComments$sadness > 0], collapse=" "),
paste(nrcComments$Text[nrcComments$surprise > 0], collapse=" "),
paste(nrcComments$Text[nrcComments$trust > 0], collapse=" ")
)
# ... some boring code hidden, I'll distribute the code if anyone wants it
# clean the text
clean.text = function(x)
{
# tolower
x = tolower(x)
# remove rt
x = gsub("rt", "", x)
# remove at
x = gsub("@\\w+", "", x)
# remove punctuation
x = gsub("[[:punct:]]", "", x)
# remove numbers
x = gsub("[[:digit:]]", "", x)
# remove links http
x = gsub("http\\w+", "", x)
# remove tabs
x = gsub("[ |\t]{2,}", "", x)
# remove blank spaces at the beginning
x = gsub("^ ", "", x)
# remove blank spaces at the end
x = gsub(" $", "", x)
return(x)
}
all = clean.text(all)
# remove stop-words
# adding extra domain specific stop words
all = removeWords(all, c(stopwords("english"), "rampton"))
# create corpus
corpus = Corpus(VectorSource(all))
# create term-document matrix
tdm = TermDocumentMatrix(corpus)
# convert as matrix
tdm = as.matrix(tdm)
# add column names
colnames(tdm) = c('anger', 'anticipation', 'disgust', 'fear',
'joy', 'sadness', 'surprise', 'trust')
# Plot comparison wordcloud
layout(matrix(c(1, 2), nrow = 2), heights = c(1, 4))
par(mar = rep(0, 4))
plot.new()
text(x = 0.5, y=0.5, 'Emotion Comparison Word Cloud')
comparison.cloud(tdm, random.order=FALSE,
colors = c("#00B2FF", "red", "#FF0099", "#6600CC",
"green", "orange", "blue", "brown"),
title.size = 1.5, max.words = 250)
wordcloud2(demoFreq[1:400, ], figPath = "~/Nextcloud/Presentations/tidyText/nhs.png", size = 1.5)
?wordcloud2
getwd()
figPath = system.file("examples/t.png",package = "wordcloud2")
figPath
source('~/.active-rstudio-document', echo=TRUE)
b
?trimws
require(stats); require(graphics)
boxplot(weight ~ feed, data = chickwts, col = "lightgray",
varwidth = TRUE, notch = TRUE, main = "chickwt data",
ylab = "Weight at six weeks (gm)")
anova(fm1 <- lm(weight ~ feed, data = chickwts))
opar <- par(mfrow = c(2, 2), oma = c(0, 0, 1.1, 0),
mar = c(4.1, 4.1, 2.1, 1.1))
plot(fm1)
par(opar)
hist(chickwts$weight)
library(tidyverse)
View(opar)
ggplot(chickwts, aes(weight)) + geom_histogram() + facet_grid( ~ feed)
ggplot(chickwts, aes(weight)) + geom_histogram() + facet_wrap( ~ feed)
summary(chickwts)
plot(women, xlab = "Height (in)", ylab = "Weight (lb)",
main = "women data: American women aged 30-39")
hist(women$height)
hist(women$height, breaks = 30)
table(women$height)
table(women$weight)
write.csv(chickwts, file = "~/chicks.csv")
?pyears
??pyears
install.packages("survival")
library(survival)
?pyears
py <- pyears(futime ~ rx, rmap=list(age=age, sex=sex, year=entry.dt),
ratetable=survexp.us)
fit1 <- pyears(Surv(stop/365.25, event) ~ cut(age + 48, c(0,50,60,70,100)) +
surgery, data = hearta, scale = 1)
data(survival)
temp.yr  <- tcut(mgus$dxyr, 55:92, labels=as.character(55:91))
temp.age <- tcut(mgus$age, 34:101, labels=as.character(34:100))
ptime <- ifelse(is.na(mgus$pctime), mgus$futime, mgus$pctime)
pstat <- ifelse(is.na(mgus$pctime), 0, 1)
# Example #2  Create the hearta data frame:
hearta <- by(heart, heart$id,
function(x)x[x$stop == max(x$stop),])
hearta <- do.call("rbind", hearta)
# Produce pyears table of death rates on the surgical arm
#  The first is by age at randomization, the second by current age
fit1 <- pyears(Surv(stop/365.25, event) ~ cut(age + 48, c(0,50,60,70,100)) +
surgery, data = hearta, scale = 1)
fit2 <- pyears(Surv(stop/365.25, event) ~ tcut(age + 48, c(0,50,60,70,100)) +
surgery, data = hearta, scale = 1)
library(survival)
library(readr)
epiData = read_csv("~/temp.csv")
fit3 = pyears(Surv(days, event) ~ tcut(age, breaks = c(15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85, 120)),
data = epiData)
fit3
fit3$pyears
library(gganimate)
library(magick)
source('~/.active-rstudio-document', echo=TRUE)
install.packages('qicharts2')
library(qicharts2)
example('qic')
vignette('qic')
vignette('qicharts2')
qic(month, n,
data     = cdi,
decimals = 0,
part     = 24,
title    = 'Hospital acquired Clostridium difficile infections',
ylab     = 'Count',
xlab     = 'Month')
vignette('qicharts2')
vignette('qicharts2')
qic(month, n,
data  = cdi,
chart = 'c',
part  = 24,
title = 'Hospital acquired Clostridium difficile infections (C chart)',
ylab  = 'Count',
xlab  = 'Month')
sample(1:10, 10)
source('~/.active-rstudio-document', echo=TRUE)
source('~/.active-rstudio-document', echo=TRUE)
barplot(a)
barplot(a, names.arg = 1:10)
library(RCurl)
shiny::runApp('Nextcloud/Packt/shinyBook3/Chapter4/gapminderEnhanced')
